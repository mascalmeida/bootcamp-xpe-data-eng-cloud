# Annotations üìú‚úçÔ∏è

## Chapter 1 - Introduction to Spark and Data Engineering

### 1.1. Big Data and Data Engineering

- Big Data Challenges:
    1. Big Data needs to be managed, stored, and persisted;
    2. Big Data needs to be interpreted and modeled;
    3. There isn‚Äôt enough memory to store Big Data;
- Distributed Computing: it works in two main ways, first partitioning the big data in smaller pieces and processing this smaller data piecing in a distributed way using many different servers (computers).
- Distributed Computing Plataforms:
    - Hadoop
    - Apache Spark
    - Apache Flink
    - Apache Storm

### 1.3. Introduction to Apache Spark

- Apache Spark concept:
    - Big Data Platform
    - Big Data processing framework
    - Engine to general-purpose distributed data
    - Open-source distributed system for Big Data
- Distributed Computing concept:
    - Implicit parallelism
    - Failure tolerance
- Apache Spark features:
    - Batch processing
    - Streaming processing
    - ML, Deep Learning
    - Data Engineering and Data Science
- Apache Spark interfaces:
    - Python, R, Scala, SQL, Java
    - Spark SQL package
    - DataFrames package
    - Streaming framework
    - MLib for machine learning
    - GraphX for data-viz

### 1.5. Advantages and Disadvantages of Spark

## Chapter 2 - ...

### 2.1 - 

### 2.2 - 

### 2.3 - 

### 2.4 - 

## Chapter 3 - ...

### 3.1 - 
